<svg id="f58f13c9-1972-416d-8207-9dc0c10c6ab0" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1400 838.37"><text transform="translate(332.86 40)" style="isolation:isolate;font-size:28px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700">Reinforcement Learning Methods for Language Models</text><text transform="translate(430.38 65)" style="isolation:isolate;font-size:16px;fill:#aaa;font-family:ArialMT, Arial">Di<tspan x="15.11" y="0" style="letter-spacing:-0.01806640625em">f</tspan><tspan x="19.27" y="0">ferent approaches to align LLMs with human preferences (NO</tspan><tspan x="456.83" y="0" style="letter-spacing:-0.01806640625em">T</tspan><tspan x="466.31" y="0" xml:space="preserve"> game</tspan><tspan x="510.78" y="0" style="letter-spacing:-0.05517578125em"> </tspan><tspan x="514.34" y="0">AI!)</tspan></text><g id="e4d70581-e188-410b-9000-f29aaa1e28dd" data-name="RLHF"><path d="M60,100H420c5.52,0,10,4.8,10,10.71V389.29c0,5.91-4.48,10.71-10,10.71H60c-5.52,0-10-4.8-10-10.71V110.71C50,104.8,54.48,100,60,100Z" style="fill:#2d2d44;stroke:#4a4a6a;stroke-width:2px"/><rect x="60" y="110" width="360" height="30" rx="5" style="fill:#45b7d1"/><text transform="translate(218.67 130)" style="isolation:isolate;font-size:16px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700">RLHF</text><text transform="translate(70 170)" style="isolation:isolate;font-size:11px;fill:#ffeb3b;font-family:Arial-BoldMT, Arial;font-weight:700">Step 1: Collect Preference Data</text><text transform="translate(70 185)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Humans rank model outputs<tspan x="144.48" y="0" xml:space="preserve" style="letter-spacing:-0.05517578125em"> A</tspan><tspan x="153.66" y="0" xml:space="preserve"> vs B</tspan></text><text transform="translate(70 200)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Create preference dataset</text><text transform="translate(70 225)" style="isolation:isolate;font-size:11px;fill:#ffeb3b;font-family:Arial-BoldMT, Arial;font-weight:700">Step 2: <tspan x="39.73" y="0" style="letter-spacing:-0.05517578125em">T</tspan><tspan x="45.84" y="0">rain Reward Model</tspan></text><text transform="translate(70 240)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Bradley-<tspan x="47.87" y="0" style="letter-spacing:-0.11083984375em">T</tspan><tspan x="53.37" y="0">erry model on preferences</tspan></text><text transform="translate(70 255)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Predicts human preference scores</text><text transform="translate(70 280)" style="isolation:isolate;font-size:11px;fill:#ffeb3b;font-family:Arial-BoldMT, Arial;font-weight:700">Step 3: R<tspan x="47.67" y="0" style="letter-spacing:-0.01806640625em">L</tspan><tspan x="54.19" y="0" xml:space="preserve"> Optimization</tspan></text><text transform="translate(70 295)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• PPO (Proximal Policy Optimization)</text><text transform="translate(70 310)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Optimize LLM against reward model</text><text transform="translate(70 325)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• K<tspan x="14.24" y="0" style="letter-spacing:-0.037109375em">L</tspan><tspan x="19.95" y="0" xml:space="preserve"> penalty to prevent drift</tspan></text><text transform="translate(70 350)" style="isolation:isolate;font-size:11px;fill:#f44;font-family:Arial-BoldMT, Arial;font-weight:700">Complexity: High</text><text transform="translate(70 365)" style="isolation:isolate;font-size:11px;fill:#45b7d1;font-family:Arial-BoldMT, Arial;font-weight:700">Performance: Excellent</text><text transform="translate(70 380)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Used by: ChatGP<tspan x="93.38" y="0" style="letter-spacing:-0.11083984375em">T</tspan><tspan x="99.38" y="0">, Claude</tspan></text></g><g id="f22ea70c-1423-4b4b-9e6e-9be0b8b86110" data-name="RLHF_chalenges"><rect x="430.47" y="148.58" width="280" height="160" rx="5" style="fill:#3d3d5c;stroke:#6a6a8a"/><text transform="translate(504.24 168.58)" style="isolation:isolate;font-size:16px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700">RLHF Challenges</text><text transform="translate(440.47 188.58)" style="isolation:isolate;font-size:11px;fill:#ff6b6b;font-family:ArialMT, Arial">Challenges:</text><text transform="translate(440.47 203.58)" style="isolation:isolate;font-size:11px;fill:#ff6b6b;font-family:ArialMT, Arial">• Reward model can be gamed</text><text transform="translate(440.47 218.58)" style="isolation:isolate;font-size:11px;fill:#ff6b6b;font-family:ArialMT, Arial">•<tspan x="3.85" y="0" style="letter-spacing:-0.01806640625em"> </tspan><tspan x="6.71" y="0" style="letter-spacing:-0.037109375em">T</tspan><tspan x="13.02" y="0">raining instability</tspan></text><text transform="translate(440.47 233.58)" style="isolation:isolate;font-size:11px;fill:#ff6b6b;font-family:ArialMT, Arial">• Expensive human annotation</text><text transform="translate(440.47 248.58)" style="isolation:isolate;font-size:11px;fill:#ff6b6b;font-family:ArialMT, Arial">• Complex 3-step process</text><text transform="translate(440.47 268.58)" style="isolation:isolate;font-size:11px;fill:#4caf50;font-family:ArialMT, Arial">Benefits:</text><text transform="translate(440.47 283.58)" style="isolation:isolate;font-size:11px;fill:#4caf50;font-family:ArialMT, Arial">• State-of-the-art results</text><text transform="translate(440.47 298.58)" style="isolation:isolate;font-size:11px;fill:#4caf50;font-family:ArialMT, Arial">• <tspan x="6.91" y="0" style="letter-spacing:-0.01806640625em">W</tspan><tspan x="17.09" y="0">ell-established method</tspan></text></g><g id="eed2479d-85e9-4823-90d6-734315c54716" data-name="DPO"><path d="M60,435.4H420c5.52,0,10,5.33,10,11.91v238.2c0,6.58-4.48,11.91-10,11.91H60c-5.52,0-10-5.33-10-11.91V447.31C50,440.73,54.48,435.4,60,435.4Z" style="fill:#2d2d44;stroke:#4a4a6a;stroke-width:2px"/><rect x="60" y="445.4" width="360" height="30" rx="5" style="fill:#4ecdc4"/><text transform="translate(222.66 465.4)" style="isolation:isolate;font-size:16px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700">DPO</text><text transform="translate(70 505.4)" style="isolation:isolate;font-size:11px;fill:#ffeb3b;font-family:Arial-BoldMT, Arial;font-weight:700">Key Innovation: Skip Reward Model</text><text transform="translate(70 525.4)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Process:</text><text transform="translate(70 540.4)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Use same preference data as RLHF</text><text transform="translate(70 555.4)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Directly optimize policy with classification loss</text><text transform="translate(70 570.4)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• No separate reward model training</text><text transform="translate(70 585.4)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• No PPO, just supervised learning</text><text transform="translate(70 610.4)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Mathematical insight:</text><text transform="translate(70 625.4)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Reparameterize R<tspan x="96.16" y="0" style="letter-spacing:-0.037109375em">L</tspan><tspan x="101.87" y="0" xml:space="preserve"> objective</tspan></text><text transform="translate(70 640.4)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Convert to classification problem</text><text transform="translate(70 665.4)" style="isolation:isolate;font-size:11px;fill:#ff9800;font-family:Arial-BoldMT, Arial;font-weight:700">Complexity: Medium</text><text transform="translate(70 680.4)" style="isolation:isolate;font-size:11px;fill:#45b7d1;font-family:Arial-BoldMT, Arial;font-weight:700">Performance: Close to RLHF</text></g><g id="baeab2f7-b9d9-4781-a016-92afda180aa7" data-name="DPO_advantanges"><rect x="77.88" y="698.37" width="280" height="140" rx="5" style="fill:#3d3d5c;stroke:#6a6a8a"/><text transform="translate(153.27 718.37)" style="isolation:isolate;font-size:16px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700">DPO<tspan x="34.67" y="0" style="letter-spacing:-0.037109375em"> </tspan><tspan x="38.52" y="0">Advantages</tspan></text><text transform="translate(87.88 738.37)" style="isolation:isolate;font-size:11px;fill:#4caf50;font-family:ArialMT, Arial">Benefits:</text><text transform="translate(87.88 753.37)" style="isolation:isolate;font-size:11px;fill:#4caf50;font-family:ArialMT, Arial">• Simpler than RLHF (no reward model)</text><text transform="translate(87.88 768.37)" style="isolation:isolate;font-size:11px;fill:#4caf50;font-family:ArialMT, Arial">• More stable training</text><text transform="translate(87.88 783.37)" style="isolation:isolate;font-size:11px;fill:#4caf50;font-family:ArialMT, Arial">• Less computational overhead</text><text transform="translate(87.88 798.37)" style="isolation:isolate;font-size:11px;fill:#4caf50;font-family:ArialMT, Arial">• Easier to implement</text><text transform="translate(87.88 818.37)" style="isolation:isolate;font-size:11px;fill:#ff6b6b;font-family:ArialMT, Arial"><tspan style="letter-spacing:-0.037109375em">T</tspan><tspan x="6.31" y="0">rade-o</tspan><tspan x="38.11" y="0" style="letter-spacing:-0.01806640625em">f</tspan><tspan x="40.97" y="0">f: Less fine-grained control</tspan></text></g><g id="e2ae0287-e0fe-4ef0-8899-5d8288760ca3" data-name="GRPO"><path d="M867.35,93.44h360c5.52,0,10,5.31,10,11.85v308c0,6.55-4.48,11.85-10,11.85h-360c-5.52,0-10-5.3-10-11.85v-308C857.35,98.75,861.83,93.44,867.35,93.44Z" style="fill:#2d2d44;stroke:#4a4a6a;stroke-width:2px"/><rect x="867.35" y="103.44" width="360" height="30" rx="5" style="fill:#96ceb4"/><text transform="translate(1023.79 123.44)" style="isolation:isolate;font-size:16px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700">GRPO</text><text transform="translate(877.35 163.44)" style="isolation:isolate;font-size:11px;fill:#ffeb3b;font-family:Arial-BoldMT, Arial;font-weight:700">Group Relative Policy Optimization</text><text transform="translate(877.35 188.44)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Key Innovation:</text><text transform="translate(877.35 203.44)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Group-based preference learning</text><text transform="translate(877.35 218.44)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Relative ranking within groups</text><text transform="translate(877.35 233.44)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• More robust to preference noise</text><text transform="translate(877.35 258.44)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Process:</text><text transform="translate(877.35 273.44)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Generate multiple responses per prompt</text><text transform="translate(877.35 288.44)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Rank responses within group</text><text transform="translate(877.35 303.44)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Optimize relative to group baseline</text><text transform="translate(877.35 318.44)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Self-play style improvement</text><text transform="translate(877.35 343.44)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Benefits:</text><text transform="translate(877.35 358.44)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Better sample e<tspan x="83.94" y="0" style="letter-spacing:-0.01806640625em">f</tspan><tspan x="86.8" y="0">ficiency</tspan></text><text transform="translate(877.35 373.44)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Reduced variance in training</text><text transform="translate(877.35 398.44)" style="isolation:isolate;font-size:11px;fill:#ff9800;font-family:Arial-BoldMT, Arial;font-weight:700">Complexity: Medium</text></g><g id="a84bdc98-24c0-459b-9709-5c2a4891d4d2" data-name="constitutional_ai"><path d="M465.1,432.88h360c5.52,0,10,5.6,10,12.5v250c0,6.91-4.48,12.5-10,12.5h-360c-5.52,0-10-5.59-10-12.5v-250C455.1,438.48,459.58,432.88,465.1,432.88Z" style="fill:#2d2d44;stroke:#4a4a6a;stroke-width:2px"/><rect x="465.1" y="442.88" width="360" height="30" rx="5" style="fill:#feca57"/><text transform="translate(564.66 462.88)" style="isolation:isolate;font-size:16px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700">CONSTITUTIONA<tspan x="131.55" y="0" style="letter-spacing:-0.01806640625em">L</tspan><tspan x="141.03" y="0" style="letter-spacing:-0.037109375em"> </tspan><tspan x="144.88" y="0">AI</tspan></text><text transform="translate(475.1 502.88)" style="isolation:isolate;font-size:11px;fill:#ffeb3b;font-family:Arial-BoldMT, Arial;font-weight:700">AI <tspan x="14.06" y="0" style="letter-spacing:-0.07421875em">T</tspan><tspan x="19.96" y="0">eaching</tspan><tspan x="61.53" y="0" style="letter-spacing:-0.037109375em"> </tspan><tspan x="64.17" y="0">AI</tspan></text><text transform="translate(475.1 527.88)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Process:</text><text transform="translate(475.1 542.88)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Define constitutional principles</text><text transform="translate(475.1 557.88)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">•<tspan x="3.85" y="0" style="letter-spacing:-0.05517578125em"> </tspan><tspan x="6.3" y="0">AI critiques its own outputs</tspan></text><text transform="translate(475.1 572.88)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">•<tspan x="3.85" y="0" style="letter-spacing:-0.05517578125em"> </tspan><tspan x="6.3" y="0">AI revises based on principles</tspan></text><text transform="translate(475.1 587.88)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">•<tspan x="3.85" y="0" style="letter-spacing:-0.01806640625em"> </tspan><tspan x="6.71" y="0" style="letter-spacing:-0.037109375em">T</tspan><tspan x="13.02" y="0">rain on self-generated improvements</tspan></text><text transform="translate(475.1 612.88)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Example Constitution:</text><text transform="translate(475.1 627.88)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Be helpful and harmless</text><text transform="translate(475.1 642.88)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Refuse harmful requests</text><text transform="translate(475.1 657.88)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Be honest about limitations</text><text transform="translate(475.1 682.88)" style="isolation:isolate;font-size:11px;fill:#4caf50;font-family:Arial-BoldMT, Arial;font-weight:700">Complexity: Low-Medium</text></g><g id="bbd76527-1f1e-4f6e-bc71-c7432ce812b6" data-name="RLAIF"><path d="M867.35,454.27h360c5.52,0,10,6,10,13.42V682.45c0,7.41-4.48,13.42-10,13.42h-360c-5.52,0-10-6-10-13.42V467.69C857.35,460.28,861.83,454.27,867.35,454.27Z" style="fill:#2d2d44;stroke:#4a4a6a;stroke-width:2px"/><rect x="867.35" y="464.27" width="360" height="30" rx="5" style="fill:#ff9ff3"/><text transform="translate(1023.8 484.27)" style="isolation:isolate;font-size:16px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700">RLAIF</text><text transform="translate(877.35 524.27)" style="isolation:isolate;font-size:11px;fill:#ffeb3b;font-family:Arial-BoldMT, Arial;font-weight:700">R<tspan x="7.94" y="0" style="letter-spacing:-0.01806640625em">L</tspan><tspan x="14.46" y="0" xml:space="preserve"> from</tspan><tspan x="41.96" y="0" style="letter-spacing:-0.037109375em"> </tspan><tspan x="44.61" y="0">AI Feedback</tspan></text><text transform="translate(877.35 549.27)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Key Idea:</text><text transform="translate(877.35 564.27)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Replace human feedback with<tspan x="154.27" y="0" style="letter-spacing:-0.05517578125em"> </tspan><tspan x="156.72" y="0">AI feedback</tspan></text><text transform="translate(877.35 579.27)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Use strong<tspan x="60.1" y="0" style="letter-spacing:-0.05517578125em"> </tspan><tspan x="62.55" y="0">AI model to rate outputs</tspan></text><text transform="translate(877.35 594.27)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Same RLHF process but with<tspan x="149.96" y="0" style="letter-spacing:-0.05517578125em"> </tspan><tspan x="152.41" y="0">AI labels</tspan></text><text transform="translate(877.35 619.27)" style="isolation:isolate;font-size:12px;fill:#fff;font-family:ArialMT, Arial">Benefits:</text><text transform="translate(877.35 634.27)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Scalable (no human annotation)</text><text transform="translate(877.35 649.27)" style="isolation:isolate;font-size:11px;fill:#ccc;font-family:ArialMT, Arial">• Consistent feedback</text><text transform="translate(877.35 674.27)" style="isolation:isolate;font-size:11px;fill:#ff9800;font-family:Arial-BoldMT, Arial;font-weight:700">Complexity: Medium</text></g></svg>