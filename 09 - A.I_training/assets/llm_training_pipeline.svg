<svg viewBox="0 0 1400 900" xmlns="http://www.w3.org/2000/svg">
  <!-- Styles with llm- prefix to avoid conflicts -->
  <defs>
    <style>
      .llm-background { fill: #1a1a2e; }
      .llm-title { fill: #ffffff; font-size: 32px; font-weight: bold; text-anchor: middle; }
      .llm-subtitle { fill: #aaaaaa; font-size: 18px; text-anchor: middle; }
      .llm-stage-bg { fill: #2d2d44; stroke: #4a4a6a; stroke-width: 2; }
      .llm-stage-title { fill: #ffffff; font-size: 16px; font-weight: bold; text-anchor: middle; }
      .llm-stage-text { fill: #ffffff; font-size: 12px; }
      .llm-stage-subtext { fill: #aaaaaa; font-size: 11px; }
      .llm-pretraining { fill: #FF6B6B; }
      .llm-sft { fill: #4ECDC4; }
      .llm-rlhf { fill: #45B7D1; }
      .llm-alternatives { fill: #96CEB4; }
      .llm-data-flow { stroke: #ffeb3b; stroke-width: 3; fill: none; }
      .llm-arrow { fill: #ffeb3b; }
      .llm-cost-high { fill: #ff4444; font-size: 12px; font-weight: bold; }
      .llm-cost-medium { fill: #ff9800; font-size: 12px; font-weight: bold; }
      .llm-cost-low { fill: #4CAF50; font-size: 12px; font-weight: bold; }
      .llm-timeline-text { fill: #ffeb3b; font-size: 11px; font-weight: bold; text-anchor: middle; }
      .llm-capability-text { fill: #4CAF50; font-size: 11px; }
      .llm-problem-text { fill: #ff6b6b; font-size: 11px; }
      .llm-example-bg { fill: #3d3d5c; stroke: #6a6a8a; stroke-width: 1; }
      .llm-metrics-text { fill: #ffffff; font-size: 10px; }
    </style>
    <marker id="llmArrow" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto" markerUnits="strokeWidth">
      <path d="M0,0 L0,6 L9,3 z" class="llm-arrow"/>
    </marker>
  </defs>
  
  <!-- Background -->
  <rect width="1400" height="900" class="llm-background"/>
  
  <!-- Main Title -->
  <text x="700" y="40" class="llm-title">Large Language Model Training Pipeline</text>
  <text x="700" y="65" class="llm-subtitle">From Raw Internet Text to Helpful AI Assistant</text>
  
  <!-- Timeline -->
  <g transform="translate(50, 100)">
    <line x1="100" y1="50" x2="1200" y2="50" class="llm-data-flow"/>
    
    <!-- Timeline labels -->
    <text x="200" y="35" class="llm-timeline-text">Months</text>
    <text x="500" y="35" class="llm-timeline-text">Days</text>
    <text x="800" y="35" class="llm-timeline-text">Hours</text>
    <text x="1100" y="35" class="llm-timeline-text">Hours</text>
  </g>
  
  <!-- Stage 1: Pre-training -->
  <g transform="translate(50, 180)">
    <rect x="0" y="0" width="300" height="200" class="llm-stage-bg" rx="10"/>
    <rect x="10" y="10" width="280" height="30" class="llm-pretraining" rx="5"/>
    <text x="150" y="30" class="llm-stage-title">PRE-TRAINING</text>
    
    <!-- Data sources -->
    <g transform="translate(20, 60)">
      <text x="0" y="15" class="llm-stage-text">Data Sources:</text>
      <text x="0" y="30" class="llm-stage-subtext">• CommonCrawl (web pages)</text>
      <text x="0" y="45" class="llm-stage-subtext">• Books, Wikipedia</text>
      <text x="0" y="60" class="llm-stage-subtext">• Code repositories</text>
      <text x="0" y="75" class="llm-stage-subtext">• Trillions of tokens</text>
    </g>
    
    <!-- Process -->
    <g transform="translate(20, 145)">
      <text x="0" y="15" class="llm-stage-text">Process: Next-token prediction</text>
      <text x="0" y="30" class="llm-cost-high">Cost: $4-10M, thousands of GPUs</text>
    </g>
    
    <!-- Arrow to next stage -->
    <path d="M 300 100 L 350 100" class="llm-data-flow" marker-end="url(#llmArrow)"/>
  </g>
  
  <!-- Base Model Output -->
  <g transform="translate(370, 220)">
    <rect x="0" y="0" width="260" height="120" class="llm-example-bg" rx="5"/>
    <text x="130" y="15" class="llm-stage-title">Base Model Output</text>
    <text x="10" y="35" class="llm-capability-text">✓ Knows language patterns</text>
    <text x="10" y="50" class="llm-capability-text">✓ Has factual knowledge</text>
    <text x="10" y="65" class="llm-capability-text">✓ Can complete text</text>
    <text x="10" y="85" class="llm-problem-text">✗ Doesn't follow instructions</text>
    <text x="10" y="100" class="llm-problem-text">✗ May be unhelpful/harmful</text>
  </g>
  
  <!-- Stage 2: Supervised Fine-Tuning -->
  <g transform="translate(380, 380)">
    <rect x="0" y="0" width="280" height="180" class="llm-stage-bg" rx="10"/>
    <rect x="10" y="10" width="260" height="30" class="llm-sft" rx="5"/>
    <text x="140" y="30" class="llm-stage-title">SUPERVISED FINE-TUNING</text>
    
    <!-- Data and process -->
    <g transform="translate(20, 60)">
      <text x="0" y="15" class="llm-stage-text">Data: Instruction-response pairs</text>
      <text x="0" y="30" class="llm-stage-subtext">• Human-written examples</text>
      <text x="0" y="45" class="llm-stage-subtext">• Thousands of samples</text>
      <text x="0" y="60" class="llm-stage-subtext">• High-quality curation</text>
      
      <text x="0" y="85" class="llm-stage-text">Process: Supervised learning</text>
      <text x="0" y="105" class="llm-cost-medium">Cost: $1-10K, days of training</text>
    </g>
    
    <!-- Arrow to next stage -->
    <path d="M 280 100 L 330 100" class="llm-data-flow" marker-end="url(#llmArrow)"/>
  </g>
  
  <!-- SFT Model Output -->
  <g transform="translate(680, 420)">
    <rect x="0" y="0" width="240" height="100" class="llm-example-bg" rx="5"/>
    <text x="120" y="15" class="llm-stage-title">SFT Model Output</text>
    <text x="10" y="35" class="llm-capability-text">✓ Follows instructions</text>
    <text x="10" y="50" class="llm-capability-text">✓ Structured responses</text>
    <text x="10" y="70" class="llm-problem-text">✗ May not align with preferences</text>
    <text x="10" y="85" class="llm-problem-text">✗ Can be unhelpful despite following</text>
  </g>
  
  <!-- Stage 3: RLHF -->
  <g transform="translate(700, 180)">
    <rect x="0" y="0" width="300" height="200" class="llm-stage-bg" rx="10"/>
    <rect x="10" y="10" width="280" height="30" class="llm-rlhf" rx="5"/>
    <text x="150" y="30" class="llm-stage-title">RLHF</text>
    
    <!-- Process steps -->
    <g transform="translate(20, 60)">
      <text x="0" y="15" class="llm-stage-text">1. Collect preference data</text>
      <text x="0" y="30" class="llm-stage-subtext">   Human ranking: A vs B</text>
      
      <text x="0" y="50" class="llm-stage-text">2. Train reward model</text>
      <text x="0" y="65" class="llm-stage-subtext">   Predict human preferences</text>
      
      <text x="0" y="85" class="llm-stage-text">3. RL optimization (PPO)</text>
      <text x="0" y="100" class="llm-stage-subtext">   Optimize against reward</text>
      
      <text x="0" y="125" class="llm-cost-medium">Cost: $1-5K, hours of training</text>
    </g>
    
    <!-- Arrow to final output -->
    <path d="M 300 100 L 350 100" class="llm-data-flow" marker-end="url(#llmArrow)"/>
  </g>
  
  <!-- Final Model Output -->
  <g transform="translate(1020, 220)">
    <rect x="0" y="0" width="260" height="120" class="llm-example-bg" rx="5"/>
    <text x="130" y="15" class="llm-stage-title">Aligned Model Output</text>
    <text x="10" y="35" class="llm-capability-text">✓ Follows instructions</text>
    <text x="10" y="50" class="llm-capability-text">✓ Helpful and harmless</text>
    <text x="10" y="65" class="llm-capability-text">✓ Aligned with human values</text>
    <text x="10" y="80" class="llm-capability-text">✓ Refuses harmful requests</text>
    <text x="10" y="100" class="llm-capability-text">✓ ChatGPT-like behavior</text>
  </g>
  
  <!-- Alternative Methods -->
  <g transform="translate(700, 420)">
    <rect x="0" y="0" width="300" height="120" class="llm-stage-bg" rx="10"/>
    <rect x="10" y="10" width="280" height="30" class="llm-alternatives" rx="5"/>
    <text x="150" y="30" class="llm-stage-title">ALTERNATIVES</text>
    
    <g transform="translate(20, 60)">
      <text x="0" y="15" class="llm-stage-text">DPO: Direct Preference Optimization</text>
      <text x="0" y="30" class="llm-stage-subtext">• Skip reward model, optimize directly</text>
      
      <text x="0" y="50" class="llm-stage-text">GRPO: Group Relative Policy Optimization</text>
      <text x="0" y="65" class="llm-stage-subtext">• Improved stability and performance</text>
      
      <text x="0" y="85" class="llm-cost-low">Cost: Lower complexity than RLHF</text>
    </g>
  </g>
  
  <!-- Performance Metrics -->
  <g transform="translate(50, 640)">
    <rect x="0" y="0" width="1300" height="120" class="llm-stage-bg" rx="10"/>
    <text x="650" y="25" class="llm-stage-title">Training Comparison</text>
    
    <!-- Comparison table -->
    <g transform="translate(50, 45)">
      <!-- Headers -->
      <text x="0" y="20" class="llm-stage-text">Stage</text>
      <text x="150" y="20" class="llm-stage-text">Data Scale</text>
      <text x="300" y="20" class="llm-stage-text">Time</text>
      <text x="450" y="20" class="llm-stage-text">Cost</text>
      <text x="600" y="20" class="llm-stage-text">Capability Gained</text>
      <text x="900" y="20" class="llm-stage-text">Limitations</text>
      
      <!-- Pre-training row -->
      <text x="0" y="40" class="llm-metrics-text">Pre-training</text>
      <text x="150" y="40" class="llm-metrics-text">Trillions of tokens</text>
      <text x="300" y="40" class="llm-metrics-text">Months</text>
      <text x="450" y="40" class="llm-cost-high">$4-10M</text>
      <text x="600" y="40" class="llm-metrics-text">Language understanding</text>
      <text x="900" y="40" class="llm-metrics-text">No instruction following</text>
      
      <!-- SFT row -->
      <text x="0" y="60" class="llm-metrics-text">SFT</text>
      <text x="150" y="60" class="llm-metrics-text">Thousands of examples</text>
      <text x="300" y="60" class="llm-metrics-text">Days</text>
      <text x="450" y="60" class="llm-cost-medium">$1-10K</text>
      <text x="600" y="60" class="llm-metrics-text">Instruction following</text>
      <text x="900" y="60" class="llm-metrics-text">May not be helpful</text>
      
      <!-- RLHF row -->
      <text x="0" y="80" class="llm-metrics-text">RLHF</text>
      <text x="150" y="80" class="llm-metrics-text">Preference comparisons</text>
      <text x="300" y="80" class="llm-metrics-text">Hours</text>
      <text x="450" y="80" class="llm-cost-medium">$1-5K</text>
      <text x="600" y="80" class="llm-metrics-text">Human alignment</text>
      <text x="900" y="80" class="llm-metrics-text">Complex to implement</text>
    </g>
  </g>
  
  <!-- Key Insight -->
  <g transform="translate(50, 790)">
    <rect x="0" y="0" width="1300" height="60" class="llm-example-bg" rx="10"/>
    <text x="650" y="25" class="llm-stage-title">Key Insight</text>
    <text x="650" y="45" class="llm-subtitle">Each stage builds on the previous: Raw text → Language model → Instruction follower → Helpful assistant</text>
  </g>
</svg>