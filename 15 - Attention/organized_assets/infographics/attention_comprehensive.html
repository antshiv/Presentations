<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Comprehensive Attention Infographic</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&family=Roboto+Mono:wght@400;700&display=swap');
        body {
            background-color: #111;
            color: #eee;
            font-family: 'Inter', sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            padding: 2rem;
        }

        .infographic-container {
            width: 100%;
            height: auto;
            max-width: 1800px;
            background-color: #222;
            border-radius: 1rem;
            padding: 2rem;
            box-shadow: 0 10px 25px rgba(0,0,0,0.5);
            overflow: hidden;
        }

        svg { overflow: visible; }
        .title { font-family: 'Inter', sans-serif; font-size: 48px; font-weight: bold; fill: #e5e7eb; }
        .subtitle { font-family: 'Inter', sans-serif; font-size: 20px; fill: #9ca3af; }
        .hpc-tag { font-family: 'Inter', sans-serif; font-size: 16px; font-weight: bold; fill: #fff; text-anchor: middle; }
        
        .section-header { font-family: 'Inter', sans-serif; font-size: 32px; font-weight: bold; fill: #3b82f6; }
        .section-subtext { font-family: 'Inter', sans-serif; font-size: 18px; fill: #9ca3af; }
        .text-dim { font-family: 'Roboto Mono', monospace; font-size: 16px; fill: #d1d5db; }
        
        .connector { stroke: #4b5563; stroke-width: 3; fill: none; marker-end: url(#arrow); }
        .connector-active { stroke: #3b82f6; stroke-width: 5; fill: none; marker-end: url(#arrow-active); }
        .arrow { fill: #4b5563; stroke: none; }
        .arrow-active { fill: #3b82f6; stroke: none; }
        
        .box-input { fill: #374151; stroke: #4b5563; stroke-width: 2; transition: all 0.3s ease-in-out; }
        .box-proc { fill: #1f2937; stroke: #60a5fa; stroke-width: 2; transition: all 0.3s ease-in-out; }
        .box-output { fill: #3b82f6; stroke: #1f2937; stroke-width: 3; transition: all 0.3s ease-in-out; }

        .text-label { font-family: 'Inter', sans-serif; font-size: 18px; font-weight: bold; fill: #e5e7eb; text-anchor: middle; }
        .text-small { font-family: 'Inter', sans-serif; font-size: 14px; fill: #9ca3af; text-anchor: middle; }

        .highlight-on-hover:hover { stroke: #3b82f6; transform: scale(1.02); }
        .highlight-on-hover:hover > .text-label, .highlight-on-hover:hover > .text-small { fill: #3b82f6; }

        .callout-box { fill: #2e3a47; stroke: #60a5fa; stroke-width: 2; }
        .callout-text { font-family: 'Inter', sans-serif; font-size: 18px; fill: #e5e7eb; text-anchor: middle; }
        .callout-code { font-family: 'Roboto Mono', monospace; font-size: 16px; fill: #34d399; text-anchor: middle; }
        .callout-title { font-family: 'Inter', sans-serif; font-size: 24px; font-weight: bold; fill: #34d399; text-anchor: middle; }
        .callout-arrow { stroke: #f87171; stroke-width: 3; marker-end: url(#arrow-red); }
        .arrow-red { fill: #f87171; stroke: none; }

        .animate-flow-path {
            stroke-dasharray: 1000;
            stroke-dashoffset: 1000;
            animation: dash 5s forwards;
            animation-timing-function: cubic-bezier(0.25, 0.1, 0.25, 1);
        }

        @keyframes dash {
            to { stroke-dashoffset: 0; }
        }

        .animate-pulse {
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); opacity: 0.8; }
            50% { transform: scale(1.05); opacity: 1; }
            100% { transform: scale(1); opacity: 0.8; }
        }
    </style>
</head>
<body>
    <div class="infographic-container">
        <svg viewBox="0 0 1800 1300" xmlns="http://www.w3.org/2000/svg">
            <defs>
                <marker id="arrow" markerWidth="10" markerHeight="10" refX="8" refY="5" orient="auto" markerUnits="strokeWidth">
                    <path d="M0,0 L10,5 L0,10 z" class="arrow" />
                </marker>
                <marker id="arrow-active" markerWidth="10" markerHeight="10" refX="8" refY="5" orient="auto" markerUnits="strokeWidth">
                    <path d="M0,0 L10,5 L0,10 z" class="arrow-active" />
                </marker>
                <marker id="arrow-red" markerWidth="10" markerHeight="10" refX="8" refY="5" orient="auto" markerUnits="strokeWidth">
                    <path d="M0,0 L10,5 L0,10 z" class="arrow-red" />
                </marker>
            </defs>

            <!-- Title and Subtitle -->
            <text x="900" y="60" text-anchor="middle" class="title">The Attention Mechanism: An HPC Deep Dive</text>
            <text x="900" y="95" text-anchor="middle" class="subtitle">From Conceptual Breakthrough to Low-Level Optimization</text>
            <rect x="750" y="115" width="300" height="35" rx="5" ry="5" fill="#3b82f6" />
            <text x="900" y="138" class="hpc-tag">The Core of an LLM</text>

            <!-- Global Dimensions Key -->
            <g transform="translate(1500, 150)">
                <text x="0" y="0" class="text-small" text-anchor="start">T = Tokens in Sequence</text>
                <text x="0" y="20" class="text-small" text-anchor="start">D = Embedding Dimension</text>
                <text x="0" y="40" class="text-small" text-anchor="start">H = Head Dimension</text>
            </g>

            <!-- Part 1: The Why (RNN vs. Attention) -->
            <g transform="translate(100, 200)">
                <text x="400" y="0" class="section-header" text-anchor="middle">Why Attention?</text>
                <text x="400" y="30" class="section-subtext" text-anchor="middle">The breakthrough that enabled parallel processing of sequences.</text>
                
                <!-- RNN Diagram -->
                <rect x="0" y="70" width="250" height="150" rx="10" ry="10" class="box-input highlight-on-hover" />
                <text x="125" y="120" class="text-label">Traditional RNN</text>
                <text x="125" y="150" class="text-small">Processes tokens one by one.</text>
                <text x="125" y="170" class="text-small">Bottleneck: O(T) complexity.</text>
                <path d="M250,145 L300,145" class="connector" />
                <rect x="300" y="130" width="100" height="30" rx="5" ry="5" class="box-proc" />
                <text x="350" y="150" class="text-small">Token 1</text>
                <path d="M400,145 L450,145" class="connector" />
                <rect x="450" y="130" width="100" height="30" rx="5" ry="5" class="box-proc" />
                <text x="500" y="150" class="text-small">Token 2</text>
                <path d="M550,145 L600,145" class="connector" />
                <rect x="600" y="130" width="100" height="30" rx="5" ry="5" class="box-proc" />
                <text x="650" y="150" class="text-small">Token 3</text>
                
                <!-- Attention Diagram -->
                <rect x="0" y="270" width="250" height="150" rx="10" ry="10" class="box-output highlight-on-hover" />
                <text x="125" y="320" class="text-label" fill="#fff">Self-Attention</text>
                <text x="125" y="350" class="text-small" fill="#fff">Processes tokens in parallel.</text>
                <text x="125" y="370" class="text-small" fill="#fff">Scales better: O(1) for compute.</text>
                <path d="M250,345 L300,345" class="connector-active animate-flow-path" style="animation-delay: 5.5s;" />
                <rect x="300" y="330" width="400" height="30" rx="5" ry="5" class="box-proc" />
                <text x="500" y="350" class="text-small">Token 1 | Token 2 | Token 3</text>
            </g>

            <!-- Part 2: The How (QKV & Pipeline) -->
            <g transform="translate(900, 350)">
                <text x="250" y="0" class="section-header">The Attention Pipeline</text>
                <text x="250" y="30" class="section-subtext">How we compute a new vector for each token.</text>
                
                <!-- Input Embeddings -->
                <rect x="100" y="70" width="300" height="60" rx="8" ry="8" class="box-input" />
                <text x="250" y="95" class="text-label">Input Embeddings (X)</text>
                <text x="250" y="115" class="text-dim" text-anchor="middle">Shape: [T x D]</text>
                
                <!-- QKV Generation -->
                <path d="M250,130 L250,200" class="connector" />
                <rect x="100" y="200" width="300" height="60" rx="8" ry="8" class="box-proc highlight-on-hover" />
                <text x="250" y="225" class="text-label">Generate Q, K, V</text>
                <text x="250" y="245" class="text-small">From X via linear layers</text>
                <path d="M250,260 L250,320" class="connector" />
                
                <!-- Q, K, V Tensors -->
                <g transform="translate(-50, 320)">
                    <rect x="0" y="0" width="150" height="70" rx="8" ry="8" class="box-input" />
                    <text x="75" y="35" class="text-label">Q</text>
                    <text x="75" y="55" class="text-dim" text-anchor="middle">Shape: [T x H]</text>
                </g>
                <g transform="translate(125, 320)">
                    <rect x="0" y="0" width="150" height="70" rx="8" ry="8" class="box-input" />
                    <text x="75" y="35" class="text-label">K</text>
                    <text x="75" y="55" class="text-dim" text-anchor="middle">Shape: [T x H]</text>
                </g>
                <g transform="translate(300, 320)">
                    <rect x="0" y="0" width="150" height="70" rx="8" ry="8" class="box-input" />
                    <text x="75" y="35" class="text-label">V</text>
                    <text x="75" y="55" class="text-dim" text-anchor="middle">Shape: [T x H]</text>
                </g>

                <!-- Q·Kᵀ and Softmax -->
                <path d="M25,390 L25,450 L125,450" class="connector" />
                <path d="M200,390 L200,450 L125,450" class="connector" />
                <rect x="125" y="430" width="150" height="40" rx="8" ry="8" class="box-proc" />
                <text x="200" y="455" class="text-label">Q·Kᵀ</text>
                <path d="M275,450 L325,450" class="connector" />
                <rect x="325" y="430" width="150" height="40" rx="8" ry="8" class="box-proc" />
                <text x="400" y="455" class="text-label">Softmax</text>
                
                <!-- Attention Scores -->
                <path d="M450,470 L450,530" class="connector" />
                <rect x="400" y="530" width="200" height="70" rx="8" ry="8" class="box-input" />
                <text x="500" y="565" class="text-label">Attention Scores</text>
                <text x="500" y="585" class="text-dim" text-anchor="middle">Shape: [T x T]</text>
                
                <!-- Scores · V -->
                <path d="M450,600 L450,660 L300,660" class="connector" />
                <path d="M375,390 L375,620 L375,660 L300,660" class="connector" />
                <rect x="150" y="640" width="150" height="40" rx="8" ry="8" class="box-proc" />
                <text x="225" y="665" class="text-label">Scores · V</text>
                <path d="M225,680 L225,740" class="connector" />
                
                <!-- Attention Output -->
                <rect x="125" y="740" width="200" height="70" rx="8" ry="8" class="box-output" />
                <text x="225" y="775" class="text-label" fill="#fff">Attention Output (Z)</text>
                <text x="225" y="795" class="text-dim" fill="#fff" text-anchor="middle">Shape: [T x D]</text>
            </g>

            <!-- Part 3: The HPC Magic -->
            <g transform="translate(100, 950)">
                <text x="400" y="0" class="section-header" text-anchor="middle">Your HPC Advantage</text>
                <text x="400" y="30" class="section-subtext" text-anchor="middle">Optimizing the core pipeline for a CPU's memory hierarchy.</text>

                <g transform="translate(0, 70)">
                    <rect x="0" y="0" width="200" height="150" rx="8" ry="8" class="box-input" />
                    <text x="100" y="30" class="text-label">Traditional Layout</text>
                    <text x="100" y="50" class="text-small">Token-Major</text>
                    <text x="100" y="80" class="text-dim" text-anchor="middle">Memory: [T x D]</text>
                    <text x="100" y="100" class="text-small">Good for linear access</text>
                    <text x="100" y="120" class="text-small">Bad for head-level cache</text>
                </g>
                <g transform="translate(220, 70)">
                    <rect x="0" y="0" width="250" height="150" rx="8" ry="8" class="box-output" />
                    <text x="120" y="30" class="text-label" fill="#fff">Your Layout</text>
                    <text x="120" y="50" class="text-small" fill="#fff">Head-Major</text>
                    <text x="120" y="80" class="text-dim" fill="#fff" text-anchor="middle">Memory: [H x T x H]</text>
                    <text x="120" y="100" class="text-small" fill="#fff">Good for head-parallel compute</text>
                    <text x="120" y="120" class="text-small" fill="#fff">Enables zero-copy projection</text>
                </g>
                
                <g transform="translate(500, 70)">
                    <rect x="0" y="0" width="400" height="150" rx="8" ry="8" class="callout-box" />
                    <text x="200" y="30" class="callout-title" style="font-size: 18px;;">The AVX-512 Engine</text>
                    <text x="200" y="60" class="callout-text" style="font-size: 14px;">Your micro-kernels use AVX-512 to process 16 floats</text>
                    <text x="200" y="80" class="callout-text" style="font-size: 14px;">per instruction, enabling massive parallelization.</text>
                    <text x="200" y="110" class="callout-code" style="font-size: 14px;">_mm512_fmadd_ps(a, b, c)</text>
                    <text x="200" y="130" class="callout-text" style="font-size: 14px;">The heart of your high-performance GEMM kernels.</text>
                </g>
            </g>
        </svg>
    </div>
</body>
</html>