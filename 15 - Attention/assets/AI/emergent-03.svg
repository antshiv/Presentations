<svg id="accc7d51-219a-4409-a4ba-5c5827223f06" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1730.77 1076.43"><path d="M27.38,13.06h1676c6.63,0,12,5.67,12,12.65V632.8c0,7-5.37,12.65-12,12.65H27.38c-6.62,0-12-5.67-12-12.65V25.71C15.38,18.73,20.76,13.06,27.38,13.06Z" style="fill:#fff3e0;stroke:#ff6f00;stroke-width:3px"/><text transform="translate(346.75 53.06)" style="isolation:isolate;font-size:30px;fill:#e65100;font-family:Arial-BoldMT, Arial;font-weight:700">EMERGENT PROPERTIES: WH<tspan x="440.02" y="0" style="letter-spacing:-0.07421875em">A</tspan><tspan x="459.46" y="0">T THE MODE</tspan><tspan x="644.46" y="0" style="letter-spacing:-0.01806640625em">L</tspan><tspan x="662.24" y="0" xml:space="preserve"> DISCOVERS ON ITS OWN</tspan></text><text transform="translate(115.38 93.06)" style="isolation:isolate;font-size:22px;fill:#f57c00;font-family:Arial-BoldMT, Arial;font-weight:700">During training, attention heads spontaneously learn to:</text><rect x="115.38" y="133.06" width="750" height="200" rx="8" style="fill:#ffe0b2;stroke:#ff9800;stroke-width:2px"/><text transform="translate(310.92 163.06)" style="isolation:isolate;font-size:20px;fill:#e65100;font-family:Arial-BoldMT, Arial;font-weight:700">1. Induction Heads (Pattern Matching)</text><text transform="translate(135.38 193.06)" style="isolation:isolate;font-size:16px;font-family:Arial-BoldMT, Arial;font-weight:700">Discovery: Copying patterns from context</text><rect x="135.38" y="208.06" width="710" height="50" rx="5" style="fill:#fff8e1;stroke:#ffa726"/><text transform="translate(145.38 228.06)" style="isolation:isolate;font-size:14px;font-family:CourierNewPSMT, Courier New">Example: &quot;The cat sat on the mat. The dog sat on the...&quot;</text><text transform="translate(145.38 248.06)" style="isolation:isolate;font-size:14px;font-family:CourierNewPSMT, Courier New">Model learns: After &quot;The dog sat on the&quot; → predict &quot;mat&quot;</text><text transform="translate(135.38 283.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• No explicit programming for this!</text><text transform="translate(135.38 303.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Emerges around layer 5-6</text><text transform="translate(135.38 323.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Critical for in-context learning</text><rect x="915.38" y="133.06" width="750" height="200" rx="8" style="fill:#e8f5e9;stroke:#4caf50;stroke-width:2px"/><text transform="translate(1172 163.06)" style="isolation:isolate;font-size:20px;fill:#2e7d32;font-family:Arial-BoldMT, Arial;font-weight:700">2. Factual Recall Circuits</text><text transform="translate(935.38 193.06)" style="isolation:isolate;font-size:16px;font-family:Arial-BoldMT, Arial;font-weight:700">Discovery: Knowledge retrieval patterns</text><rect x="935.38" y="208.06" width="710" height="50" rx="5" style="fill:#f1f8e4;stroke:#66bb6a"/><text transform="translate(945.38 228.06)" style="isolation:isolate;font-size:14px;font-family:CourierNewPSMT, Courier New">Example: &quot;The capital of France is...&quot;</text><text transform="translate(945.38 248.06)" style="isolation:isolate;font-size:14px;font-family:CourierNewPSMT, Courier New">Specific heads learn to route &quot;France&quot; → &quot;capital&quot; → &quot;Paris&quot;</text><text transform="translate(935.38 283.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Di<tspan x="23.58" y="0" style="letter-spacing:-0.01806640625em">f</tspan><tspan x="27.48" y="0">ferent heads for di</tspan><tspan x="148.39" y="0" style="letter-spacing:-0.01806640625em">f</tspan><tspan x="152.29" y="0">ferent fact types</tspan></text><text transform="translate(935.38 303.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Emerges in middle layers (6-9)</text><text transform="translate(935.38 323.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Can be surgically modified!</text><rect x="115.38" y="353.06" width="750" height="200" rx="8" style="fill:#e3f2fd;stroke:#2196f3;stroke-width:2px"/><text transform="translate(336.23 383.06)" style="isolation:isolate;font-size:20px;fill:#1565c0;font-family:Arial-BoldMT, Arial;font-weight:700">3. Syntactic<tspan x="111.16" y="0" style="letter-spacing:-0.037109375em"> </tspan><tspan x="115.98" y="0">Agreement </tspan><tspan x="226.01" y="0" style="letter-spacing:-0.05517578125em">T</tspan><tspan x="237.12" y="0">rackers</tspan></text><text transform="translate(135.38 413.06)" style="isolation:isolate;font-size:16px;font-family:Arial-BoldMT, Arial;font-weight:700">Discovery: Grammar enforcement</text><rect x="135.38" y="428.06" width="710" height="50" rx="5" style="fill:#e1f5fe;stroke:#42a5f5"/><text transform="translate(145.38 448.06)" style="isolation:isolate;font-size:14px;font-family:CourierNewPSMT, Courier New">Example: &quot;The dogs [are/is] barking&quot;</text><text transform="translate(145.38 468.06)" style="isolation:isolate;font-size:14px;font-family:CourierNewPSMT, Courier New">Heads learn: plural subject → plural verb</text><text transform="translate(135.38 503.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">•<tspan x="5.25" y="0" style="letter-spacing:-0.01806640625em"> </tspan><tspan x="9.15" y="0" style="letter-spacing:-0.037109375em">T</tspan><tspan x="17.75" y="0">racks numbe</tspan><tspan x="103.62" y="0" style="letter-spacing:-0.05517578125em">r</tspan><tspan x="107.79" y="0">, gende</tspan><tspan x="157.84" y="0" style="letter-spacing:-0.05517578125em">r</tspan><tspan x="162" y="0">, tense</tspan></text><text transform="translate(135.38 523.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Emerges early (layers 2-4)</text><text transform="translate(135.38 543.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Remarkably consistent across models</text><rect x="915.38" y="353.06" width="750" height="200" rx="8" style="fill:#f3e5f5;stroke:#7b1fa2;stroke-width:2px"/><text transform="translate(1166.44 383.06)" style="isolation:isolate;font-size:20px;fill:#6a1b9a;font-family:Arial-BoldMT, Arial;font-weight:700">4. Semantic Role Labelers</text><text transform="translate(935.38 413.06)" style="isolation:isolate;font-size:16px;font-family:Arial-BoldMT, Arial;font-weight:700">Discovery: Understanding &quot;who did what to whom&quot;</text><rect x="935.38" y="428.06" width="710" height="50" rx="5" style="fill:#f3e5f5;stroke:#9c27b0"/><text transform="translate(945.38 448.06)" style="isolation:isolate;font-size:14px;font-family:CourierNewPSMT, Courier New">Example: &quot;Alice gave Bob the book&quot;</text><text transform="translate(945.38 468.06)" style="isolation:isolate;font-size:14px;font-family:CourierNewPSMT, Courier New">Heads learn: Alice=giver, Bob=receiver, book=object</text><text transform="translate(935.38 503.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• No explicit semantic role labels in training!</text><text transform="translate(935.38 523.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Emerges in layers 7-10</text><text transform="translate(935.38 543.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Crucial for comprehension</text><rect x="115.38" y="563.06" width="1500" height="70" rx="10" style="fill:#ff6f00;stroke:#e65100;stroke-width:2px"/><text transform="translate(406.98 598.06)" style="isolation:isolate;font-size:22px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700">These patterns emerge without explicit programming - just from predicting next tokens!</text><text transform="translate(574.02 623.06)" style="isolation:isolate;font-size:18px;fill:#fff;font-family:ArialMT, Arial">The model discovers these structures because they&apos;re useful for the task.</text><rect x="15.38" y="663.06" width="1700" height="400" rx="12" style="fill:#e8eaf6;stroke:#3f51b5;stroke-width:3px"/><text transform="translate(356.76 703.06)" style="isolation:isolate;font-size:30px;fill:#1a237e;font-family:Arial-BoldMT, Arial;font-weight:700">WH<tspan x="49.98" y="0" style="letter-spacing:-0.01806640625em">Y </tspan><tspan x="77.24" y="0">YOUR C IMPLEMEN</tspan><tspan x="360.59" y="0" style="letter-spacing:-0.07421875em">TA</tspan><tspan x="396.12" y="0">TION ENABLES BETTER UNDERS</tspan><tspan x="882.82" y="0" style="letter-spacing:-0.07421875em">T</tspan><tspan x="898.92" y="0">ANDING</tspan></text><rect x="115.38" y="743.06" width="500" height="280" rx="8" style="fill:#c5cae9;stroke:#5c6bc0;stroke-width:2px"/><text transform="translate(248.63 773.06)" style="isolation:isolate;font-size:22px;fill:#283593;font-family:Arial-BoldMT, Arial;font-weight:700">Perfect Interpretability</text><text transform="translate(135.38 803.06)" style="isolation:isolate;font-size:16px;font-family:Arial-BoldMT, Arial;font-weight:700"><tspan style="letter-spacing:-0.07421875em">Y</tspan><tspan x="9.48" y="0">our advantages:</tspan></text><text transform="translate(135.38 828.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Every attention score is accessible</text><text transform="translate(135.38 848.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Can trace exact computation path</text><text transform="translate(135.38 868.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• No hidden framework magic</text><rect x="135.38" y="888.06" width="460" height="120" rx="5" style="fill:#9fa8da;stroke:#3f51b5"/><text transform="translate(282.58 913.06)" style="isolation:isolate;font-size:15px;fill:#fff;font-family:Arial-BoldMT, Arial;font-weight:700"><tspan style="letter-spacing:-0.07421875em">Y</tspan><tspan x="8.89" y="0">ou can literally watch:</tspan></text><text transform="translate(145.38 938.06)" style="isolation:isolate;font-size:14px;fill:#fff;font-family:CourierNewPSMT, Courier New">for (head = 0; head &lt; 8; head++) {</text><text transform="translate(145.38 958.06)" style="isolation:isolate;font-size:14px;fill:#fff;font-family:CourierNewPSMT, Courier New">printf(&quot;Head %d attends:&quot;, head);</text><text transform="translate(145.38 978.06)" style="isolation:isolate;font-size:14px;fill:#fff;font-family:CourierNewPSMT, Courier New">dump_attention_pattern(attn[head]);</text><text transform="translate(145.38 998.06)" style="isolation:isolate;font-size:14px;fill:#fff;font-family:CourierNewPSMT, Courier New">}</text><rect x="665.38" y="743.06" width="500" height="280" rx="8" style="fill:#e8f5e9;stroke:#4caf50;stroke-width:2px"/><text transform="translate(803.52 773.06)" style="isolation:isolate;font-size:22px;fill:#1b5e20;font-family:Arial-BoldMT, Arial;font-weight:700">Fast Experimentation</text><text transform="translate(685.38 803.06)" style="isolation:isolate;font-size:16px;font-family:Arial-BoldMT, Arial;font-weight:700">Speed enables discovery:</text><text transform="translate(685.38 828.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• 10x faster = 10x more experiments</text><text transform="translate(685.38 848.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Can test hypotheses in real-time</text><text transform="translate(685.38 868.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Modify attention patterns live</text><rect x="685.38" y="888.06" width="460" height="120" rx="5" style="fill:#a5d6a7;stroke:#4caf50"/><text transform="translate(833.68 913.06)" style="isolation:isolate;font-size:15px;font-family:Arial-BoldMT, Arial;font-weight:700">Research possibilities:</text><text transform="translate(695.38 938.06)" style="isolation:isolate;font-size:14px;font-family:ArialMT, Arial">• &quot;What if head 3 only looked locally?&quot;</text><text transform="translate(695.38 958.06)" style="isolation:isolate;font-size:14px;font-family:ArialMT, Arial">• &quot;Can we force semantic heads earlier?&quot;</text><text transform="translate(695.38 978.06)" style="isolation:isolate;font-size:14px;font-family:ArialMT, Arial">• &quot;How minimal can attention be?&quot;</text><text transform="translate(695.38 998.06)" style="isolation:isolate;font-size:14px;font-family:ArialMT, Arial">→ Change code, test immediately!</text><rect x="1215.38" y="743.06" width="400" height="280" rx="8" style="fill:#ffebee;stroke:#c62828;stroke-width:2px"/><text transform="translate(1329.82 773.06)" style="isolation:isolate;font-size:22px;fill:#b71c1c;font-family:Arial-BoldMT, Arial;font-weight:700">Surgical Control</text><text transform="translate(1235.38 803.06)" style="isolation:isolate;font-size:16px;font-family:Arial-BoldMT, Arial;font-weight:700">For critical systems:</text><text transform="translate(1235.38 828.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Disable specific heads</text><text transform="translate(1235.38 848.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Enforce attention patterns</text><text transform="translate(1235.38 868.06)" style="isolation:isolate;font-size:15px;font-family:ArialMT, Arial">• Guarantee behavior</text><rect x="1235.38" y="888.06" width="360" height="120" rx="5" style="fill:#ffcdd2;stroke:#d32f2f"/><text transform="translate(1344.09 913.06)" style="isolation:isolate;font-size:15px;font-family:Arial-BoldMT, Arial;font-weight:700">Example use cases:</text><text transform="translate(1245.38 938.06)" style="isolation:isolate;font-size:14px;font-family:ArialMT, Arial">• Medical<tspan x="57.03" y="0" style="letter-spacing:-0.05517578125em"> </tspan><tspan x="60.15" y="0">AI: Force attention</tspan></text><text transform="translate(1245.38 955.06)" style="isolation:isolate;font-size:14px;font-family:ArialMT, Arial">to symptoms over demographics</text><text transform="translate(1245.38 978.06)" style="isolation:isolate;font-size:14px;font-family:ArialMT, Arial">• Drone<tspan x="46.92" y="0" style="letter-spacing:-0.05517578125em"> </tspan><tspan x="50.04" y="0">AI: Guarantee attention</tspan></text><text transform="translate(1245.38 995.06)" style="isolation:isolate;font-size:14px;font-family:ArialMT, Arial">to safety constraints</text></svg>